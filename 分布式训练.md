# PyTorch 分布式训练

## DDP

1. 相关概念  
(1) **group或者world**: 进程组(大部分情况下DDP的各个进程是在同一个进程组里), world内的所有process都可以互相通信;  
(2) **world_size**: 总的进程数量(原则上一个p;rocess占用一个GPU是较优的);  
(3) **rank**: 当前进程的序号, 用于进程之间通讯, rank=0的主机为mask节点;  
(4) **local_rank**: 当前进程所对应的GPU号;  
(5) **node**: 可以理解为一个server, 即机器的数量.  
例如:  
4台机器, 每台机器8张卡, 通过`init_process_group()`对进程组进行初始化, 然后可以通过`get_world_size()`获得到**world_size=32**, 再通过`get_rank()`获取到所有进程的编号**0~31**, 在每台机器上, **local_rank**为**0~8**.GPU之间通信的方式是**nccl**, 全称是Nvidia Collective Communication Library.  
<br/>
2. torchrun
很多SOTA论文的代码都是用的torchrun, torchrun后紧跟的是关于分布式训练的参数, 分布式训练的参数指定完接.py文件, .py文件后是.py里的--args等

参数的意义:

`--nndoes`: 节点的数量, 节点就是机器数量, 要在几台服务器/电脑上运行这个代码, 如果这里直接是`--standalone` 后面没有数字就代表单机运行

`--nproc_per_node`: 表示要使用的GPU的数量, 如果是`--nproc_per_node=gpu`, 就表示使用所有可用的gpu

`--node_rank`: 当前这台机器的rank, 如果是单机运行肯定就是0了;

`--master_addr`和`--master_port`: 分别是主节点的IP地址和端口号.


## HuggingFace Accelerate




