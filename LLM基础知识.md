# 大模型基础知识

## 大模型推理和训练占用的显存怎么计算

1. 推理: 1B模型推理是需要占用多少显存?(计算出1B后,7B,14B就可以算出来了)

- 全精度推理时, 1个float32类型的参数会占用4个字节, 1B模型有10亿个参数, 每个参数占用4个字节并且

$$
1G=1024M=1024^{2}KB=1024^{3}Byte \\
\frac{10^{9} * 4}{1024^{3}}=3.725G\approx 4G
$$

$\Longrightarrow$**使用全精度部署1B的模型需要占用4G的显存**

| dtype                | 1B（10亿）参数需要占用内存 |
|----------------------|----------------------------|
| Float32 (全精度)     | 4G                         |
| fp16/bf16 (半精度)   | 2G                         |
| int8                 | 1G                         |
| int4                 | 0.5G                       |

$\Longrightarrow$7B全精度部署至少需要28G的显存, 13B至少52G, 65B至少260G...  
2. 训练

- 大模型训练过程中哪些参数需要保存?

与推理过程不同的是, 大模型在训练过程中除了要加载模型的参数外, 还需要储存模型的梯度值和优化器的状态, 根据反向传播的基本原理:
$$
\theta_{n+1}=\theta_{n}-\alpha\nabla\mathcal{L}(\theta_{n})
$$

一个模型参数$\theta_{n}$就对应一个梯度值, 因此梯度值与模型参数占用的显存是相同的, 优化器用于更新梯度, 不同的优化器占用显存的情况也不同, 上式中是最简单的SGD, 因为只使用了一阶动量的信息, 因此和模型参数占用的显存相同, 但是更为流行的Adam优化器占用的显存就是模型参数所占用的显存的2倍, 因此仅仅是模型参数,梯度值和优化器这三个部分, **大模型所占用的显存就是模型推理的3倍！** 此外还有激活值(由层数决定), 训练数据(涉及到batch_size, 上下文长度), 缓存和驱动等等.

如果再用一些炫酷的训练方法如PPO训练等, 训练时所占用的显存还会进一步增加.
